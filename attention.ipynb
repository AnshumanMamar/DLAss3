{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import heapq\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val=torch.cuda.is_available()\n",
    "if val == 1:\n",
    "    device= torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('gpu')\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(params):\n",
    "    dataset_path = params['dataset_path']\n",
    "    train_data = csv.reader(open(dataset_path + '/hin/hin_train.csv',encoding='utf8'))\n",
    "    val_data = csv.reader(open(dataset_path + '/hin/hin_valid.csv',encoding='utf8'))\n",
    "    test_data = csv.reader(open(dataset_path + '/hin/hin_test.csv',encoding='utf8'))\n",
    "    train_translations = []\n",
    "    test_words=[]\n",
    "    val_translations = []\n",
    "    val_words=[]\n",
    "    train_words =[]\n",
    "    test_translations = []\n",
    "    pad=''\n",
    "    start='$'\n",
    "    end ='&' \n",
    "    train_data_list = list(train_data)\n",
    "    train_len = len(train_data_list)\n",
    "    i = 0\n",
    "    while i < train_len:\n",
    "        pair = train_data_list[i]\n",
    "        train_words.append(pair[0] + end)\n",
    "        train_translations.append(start + pair[1] + end)\n",
    "        i += 1  \n",
    "    \n",
    "    i=0\n",
    "    val_data_list = list(val_data)\n",
    "    val_len = len(val_data_list)\n",
    "    while i < val_len :\n",
    "        pair=val_data_list[i]\n",
    "        val_words.append(pair[0]+end)\n",
    "        val_translations.append(start+pair[1]+end)\n",
    "        i+=1\n",
    "        \n",
    "    i=0\n",
    "    test_data_list = list(test_data)\n",
    "    test_len = len(test_data_list)\n",
    "    while i < test_len :\n",
    "        pair=test_data_list[i]\n",
    "        test_words.append(pair[0]+end)\n",
    "        test_translations.append(start+pair[1]+end)\n",
    "        i+=1   \n",
    "        \n",
    " \n",
    "    \n",
    "    test_words =np.array(test_words)\n",
    "    train_translations = np.array(train_translations)\n",
    "    val_translations =np.array(val_translations)\n",
    "    train_words = np.array(train_words)\n",
    "    test_translations = np.array(test_translations)\n",
    "    val_words =np.array(val_words)\n",
    "    \n",
    "    \n",
    "    \n",
    "    output_vocab,input_vocab = set() , set()\n",
    "    i = 0\n",
    "    word_len=len(train_words)\n",
    "    while i < word_len :\n",
    "        word = train_words[i]\n",
    "        character_index = 0\n",
    "        while character_index < len(word):\n",
    "            character = word[character_index]\n",
    "            input_vocab.add(character)\n",
    "            character_index += 1\n",
    "        i += 1         \n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    word_len=len(val_words)\n",
    "    while i < word_len :\n",
    "        word = val_words[i]\n",
    "        character_index = 0\n",
    "        while character_index < len(word):\n",
    "            character = word[character_index]\n",
    "            input_vocab.add(character)\n",
    "            character_index += 1\n",
    "        i += 1\n",
    "    \n",
    "    i = 0\n",
    "    word_len=len(test_words)\n",
    "    while i < word_len :\n",
    "        word = test_words[i]\n",
    "        character_index = 0\n",
    "        while character_index < len(word):\n",
    "            character = word[character_index]\n",
    "            input_vocab.add(character)\n",
    "            character_index += 1\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    word_len=len(train_translations)\n",
    "    while i < word_len :\n",
    "        word = train_translations[i]\n",
    "        character_index = 0\n",
    "        while character_index < len(word):\n",
    "            character = word[character_index]\n",
    "            output_vocab.add(character)\n",
    "            character_index += 1\n",
    "        i += 1\n",
    "        \n",
    "    i = 0\n",
    "    word_len=len(val_translations)\n",
    "    while i < word_len :\n",
    "        word = val_translations[i]\n",
    "        character_index = 0\n",
    "        while character_index < len(word):\n",
    "            character = word[character_index]\n",
    "            output_vocab.add(character)\n",
    "            character_index += 1\n",
    "        i += 1\n",
    "        \n",
    "    i = 0\n",
    "    word_len=len(test_translations)\n",
    "    while i < word_len :\n",
    "        word = test_translations[i]\n",
    "        character_index = 0\n",
    "        while character_index < len(word):\n",
    "            character = word[character_index]\n",
    "            output_vocab.add(character)\n",
    "            character_index += 1\n",
    "        i += 1\n",
    "    \n",
    "    output_vocab.remove(start)\n",
    "    input_vocab.remove(end)\n",
    "    output_vocab.remove(end)\n",
    "    \n",
    "    output_vocab= [pad, start, end] + list(sorted(output_vocab))\n",
    "    input_vocab = [pad, start, end] + list(sorted(input_vocab))\n",
    "            \n",
    " \n",
    "    output_index,input_index = {char: idx for idx, char in enumerate(output_vocab)},{char: idx for idx, char in enumerate(input_vocab)}\n",
    "    output_index_rev,input_index_rev = {idx: char for char, idx in output_index.items()},{idx: char for char, idx in input_index.items()}\n",
    "    \n",
    "\n",
    "    max_len = max(max([len(word) for word in np.hstack((train_words, test_words, val_words))]), max([len(word) for word in np.hstack((train_translations, val_translations, test_translations))]))\n",
    "        \n",
    "    preprocessed_data = {\n",
    "        'SOS' : start,\n",
    "        'EOS' : end,\n",
    "        'PAD' : pad,\n",
    "        'train_words' : train_words,\n",
    "        'train_translations' : train_translations,\n",
    "        'val_words' : val_words,\n",
    "        'val_translations' : val_translations,\n",
    "        'test_words' : test_words,\n",
    "        'test_translations' : test_translations,\n",
    "        'max_enc_len' : max([len(word) for word in np.hstack((train_words, test_words, val_words))]),\n",
    "        'max_dec_len' : max([len(word) for word in np.hstack((train_translations, val_translations, test_translations))]),\n",
    "        'max_len' : max_len,\n",
    "        'input_index' : input_index,\n",
    "        'output_index' : output_index,\n",
    "        'input_index_rev' : input_index_rev,\n",
    "        'output_index_rev' : output_index_rev\n",
    "    }\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor(preprocessed_data):\n",
    "    prop_data=preprocessed_data['max_len']\n",
    "    leng=len(preprocessed_data['train_words'])\n",
    "    d_type='int64'\n",
    "    input_data = np.zeros((prop_data,leng), dtype = d_type)\n",
    "    output_data = np.zeros((prop_data,leng), dtype = d_type)\n",
    "    leng=len(preprocessed_data['val_words'])\n",
    "    val_input_data = np.zeros((prop_data,leng), dtype = d_type)\n",
    "    val_output_data = np.zeros((prop_data,leng), dtype = d_type)\n",
    "    leng=len(preprocessed_data['test_words'])\n",
    "    test_input_data = np.zeros((prop_data,leng), dtype = d_type)\n",
    "    test_output_data = np.zeros((prop_data,leng), dtype = d_type)\n",
    "    \n",
    "\n",
    "    idx = 0\n",
    "    while idx < len(preprocessed_data['train_words']):\n",
    "        w = preprocessed_data['train_words'][idx]\n",
    "        t = preprocessed_data['train_translations'][idx]\n",
    "\n",
    "        i = 0\n",
    "        while i < len(w):\n",
    "            char = w[i]\n",
    "            input_data[i, idx] = preprocessed_data['input_index'][char]\n",
    "            i += 1\n",
    "\n",
    "        i = 0\n",
    "        while i < len(t):\n",
    "            char = t[i]\n",
    "            output_data[i, idx] = preprocessed_data['output_index'][char]\n",
    "            i += 1\n",
    "        idx += 1            \n",
    "        \n",
    "\n",
    "            \n",
    "    idx = 0\n",
    "    while idx < len(preprocessed_data['val_words']):\n",
    "        w = preprocessed_data['val_words'][idx]\n",
    "        t = preprocessed_data['val_translations'][idx]\n",
    "\n",
    "        i = 0\n",
    "        while i < len(w):\n",
    "            char = w[i]\n",
    "            val_input_data[i, idx] = preprocessed_data['input_index'][char]\n",
    "            i += 1\n",
    "\n",
    "        i = 0\n",
    "        while i < len(t):\n",
    "            char = t[i]\n",
    "            val_output_data[i, idx] = preprocessed_data['output_index'][char]\n",
    "            i += 1\n",
    "        idx += 1            \n",
    "        \n",
    "            \n",
    "    idx = 0\n",
    "    while idx < len(preprocessed_data['test_words']):\n",
    "        w = preprocessed_data['test_words'][idx]\n",
    "        t = preprocessed_data['test_translations'][idx]\n",
    "\n",
    "        i = 0\n",
    "        while i < len(w):\n",
    "            char = w[i]\n",
    "            test_input_data[i, idx] = preprocessed_data['input_index'][char]\n",
    "            i += 1\n",
    "\n",
    "        i = 0\n",
    "        while i < len(t):\n",
    "            char = t[i]\n",
    "            test_output_data[i, idx] = preprocessed_data['output_index'][char]\n",
    "            i += 1\n",
    "        idx += 1            \n",
    "        \n",
    "            \n",
    "            \n",
    "    output_data=torch.tensor(output_data, dtype = torch.int64)\n",
    "    input_data = torch.tensor(input_data,dtype = torch.int64)\n",
    "    val_output_data=torch.tensor(val_output_data, dtype = torch.int64)\n",
    "    val_input_data = torch.tensor(val_input_data,dtype = torch.int64)\n",
    "    test_output_data=torch.tensor(test_output_data, dtype = torch.int64)\n",
    "    test_input_data= torch.tensor(test_input_data,dtype = torch.int64)\n",
    "    \n",
    "    tensors = {\n",
    "        'input_data' : input_data,\n",
    "        'output_data' : output_data,\n",
    "        'val_input_data' : val_input_data,\n",
    "        'val_output_data' : val_output_data, \n",
    "        'test_input_data' : test_input_data,\n",
    "        'test_output_data' : test_output_data\n",
    "    }\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        val=hidden_size\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = val\n",
    "    def dot_score(self,hidden_state, encoder_states):\n",
    "        cal = torch.sum(hidden_state * encoder_states, dim=2)\n",
    "        return cal\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        cal = F.softmax(self.dot_score(hidden, encoder_outputs).t(), dim=1).unsqueeze(1)\n",
    "        return cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, params, preprocessed_data):\n",
    "        hd='hidden_size'\n",
    "        dp='dropout'\n",
    "        super(Encoder_Attention, self).__init__() \n",
    "        self.bi_directional,self.cell_type = params['bi_dir'],params['cell_type']\n",
    "        leng=len(preprocessed_data['input_index'])\n",
    "        self.dropout,self.embedding = nn.Dropout(params[dp]),nn.Embedding(leng, params[es])\n",
    "        self.hidden_size = params[hd]\n",
    "        val=self.cell_type\n",
    "        nm='num_layers_enc'\n",
    "        es='embedding_size' \n",
    "        if val == 'GRU':\n",
    "            self.cell = nn.GRU(params[es], params[hd], params[nm], dropout = params[dp], bidirectional = self.bi_directional)\n",
    "        if val == 'RNN':\n",
    "            self.cell = nn.RNN(params[es], params[hd], params[nm], dropout = params[dp], bidirectional = self.bi_directional)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoder_states, hidden = self.cell(self.dropout(self.embedding(x)))\n",
    "        val=self.bi_directional\n",
    "        if val:\n",
    "            encoder_states = encoder_states[:, :, :self.hidden_size] + encoder_states[:, : ,self.hidden_size:]\n",
    "        return encoder_states, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_Attention(nn.Module):\n",
    "    def __init__(self, params, preprocessed_data):\n",
    "        \n",
    "        # Initialize the Decoder_Attention module\n",
    "        super(Decoder_Attention, self).__init__()\n",
    "        dp = 'dropout'\n",
    "        \n",
    "        # Define dropout layer and embedding layer\n",
    "        self.dropout = nn.Dropout(params[dp])\n",
    "        ct,nm = 'cell_type','num_layers_dec'\n",
    "        self.num_layers,self.cell_type= params[nm] , params[ct]\n",
    "        es = 'embedding_size'\n",
    "        leng = len(preprocessed_data['output_index'])\n",
    "        self.embedding = nn.Embedding(leng, params[es])\n",
    "        hs = 'hidden_size'\n",
    "        val=self.cell_type\n",
    "        \n",
    "        # Initialize RNN cell based on cell_type\n",
    "        if val == 'GRU':\n",
    "            self.cell = nn.GRU(params[es], params[hs], self.num_layers, dropout = params[dp])\n",
    "        if val == 'RNN':\n",
    "            self.cell = nn.RNN(params[es], params[hs], self.num_layers, dropout = params[dp])\n",
    "        val = params[hs] * 2\n",
    "        leng = len(preprocessed_data['output_index'])\n",
    "        self.fc , self.concat = nn.Linear(params[hs], leng),nn.Linear(val, params[hs])\n",
    "        self.log_softmax , self.attn = nn.LogSoftmax(dim=1),Attention(params[hs])\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        \n",
    "        # Perform forward pass of the Decoder_Attention module\n",
    "        # Embed input token (unsqueeze to add batch dimension)\n",
    "        outputs, (hidden) = self.cell(self.dropout(self.embedding(x.unsqueeze(0))), hidden)\n",
    "        context = self.attn(outputs, encoder_states).bmm(encoder_states.transpose(0, 1))\n",
    "        return self.log_softmax(self.fc(torch.tanh(self.concat(torch.cat((outputs.squeeze(0), context.squeeze(1)), 1))))), hidden, attention_weights.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sequence-to-sequence model with attention mechanism\n",
    "class Seq2Seq_Attention(nn.Module):\n",
    "    # Initialize the Seq2Seq_Attention module\n",
    "    def __init__(self, encoder, decoder, params,  preprocessed_data):\n",
    "        super(Seq2Seq_Attention, self).__init__()\n",
    "        # Extract necessary parameters from the params dictionary\n",
    "        nm='num_layers_dec'\n",
    "        leng=len(preprocessed_data['output_index'])\n",
    "        self.output_index_len = leng\n",
    "        tf= 'teacher_fr'\n",
    "        self.tfr = params[tf]\n",
    "        self.num_layers_dec = params[nm]\n",
    "        \n",
    "        # Set encoder and decoder modules\n",
    "        self.encoder  = encoder\n",
    "        self.decoder  = decoder \n",
    "        \n",
    "        \n",
    "    def forward(self, source, target):\n",
    "        # Perform forward pass of the Seq2Seq_Attention module\n",
    "        \n",
    "        # Initialize decoder input (start token)\n",
    "        x = target[0,:]\n",
    "        \n",
    "        # Encode the source sequence using the encoder\n",
    "        encoder_op, hidden = self.encoder(source)\n",
    "        \n",
    "        # Initialize output tensor for predictions\n",
    "        outputs = torch.zeros(target.shape[0], source.shape[1], self.output_index_len)\n",
    "        outputs=outputs.to(device)\n",
    "        \n",
    "        # Limit decoder hidden state to the specified number of layers\n",
    "        hidden =  hidden[:self.decoder.num_layers]\n",
    "        t = 1\n",
    "        while t < target.shape[0] :  \n",
    "            # Perform decoding step using the decoder module\n",
    "            output, hidden, _ = self.decoder(x, encoder_op, hidden, None)\n",
    "            # Determine the next input token based on teacher forcing ratio\n",
    "            best_guess = output.argmax(1)\n",
    "            # Store the output predictions\n",
    "            outputs[t] = output\n",
    "            x = best_guess if random.random() >= self.tfr else target[t]\n",
    "            t+=1\n",
    "        # Return the predicted outputs from the decoder    \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an Encoder module with attention using LSTM\n",
    "class Encoder_Attention_LSTM(nn.Module):\n",
    "    ct='cell_type'\n",
    "    bi='bi_dir'\n",
    "    def __init__(self, params, preprocessed_data):\n",
    "        \n",
    "        #Initialize the Encoder_Attention_LSTM module\n",
    "        super(Encoder_Attention_LSTM, self).__init__()\n",
    "        self.cell_type = params['cell_type']\n",
    "        self.bi_directional = params['bi_dir']\n",
    "        es='embedding_size'\n",
    "        leng=len(preprocessed_data['input_index'])\n",
    "        self.embedding = nn.Embedding(leng, params[es])\n",
    "        dp='dropout'\n",
    "        hs='hidden_size'\n",
    "        self.hidden_size = params[hs]\n",
    "        nm='num_layers_enc'\n",
    "        self.dropout = nn.Dropout(params[dp])\n",
    "        \n",
    "        # Initialize LSTM cell\n",
    "        self.cell = nn.LSTM(params[es], params[hs], params[nm], dropout = params[dp], bidirectional = self.bi_directional)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform forward pass of the Encoder_Attention_LSTM module\n",
    "        \n",
    "        # Embed the input sequence\n",
    "        encoder_states, (hidden, cell) = self.cell(self.dropout(self.embedding(x)))\n",
    "        \n",
    "        # If bidirectional, concatenate the states from both directions\n",
    "        val=self.bi_directional\n",
    "        if val:\n",
    "            encoder_states = encoder_states[:, :, :self.hidden_size] + encoder_states[:, : ,self.hidden_size:]\n",
    "        \n",
    "        # Return encoder, hidden and cell states    \n",
    "        return encoder_states, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Decoder module with attention using LSTM\n",
    "class Decoder_Attention_LSTM(nn.Module):\n",
    "    def __init__(self, params, preprocessed_data):\n",
    "        \n",
    "        # Initialize the Decoder_Attention_LSTM module\n",
    "        super(Decoder_Attention_LSTM, self).__init__()\n",
    "        nm='num_layers_dec'\n",
    "        dp='dropout'\n",
    "        \n",
    "        # Set up dropout layer\n",
    "        self.dropout = nn.Dropout(params[dp])\n",
    "        self.num_layers = params[nm]\n",
    "        ot='output_index'\n",
    "        \n",
    "        # Initialize embedding layer based on output vocabulary size and embedding size\n",
    "        leng=len(preprocessed_data[ot])\n",
    "        es='embedding_size'\n",
    "        self.embedding = nn.Embedding(leng, params[es])\n",
    "        hs='hidden_size'\n",
    "        \n",
    "        # Initialize LSTM cell for decoding\n",
    "        self.cell = nn.LSTM(params[es], params[hs], self.num_layers, dropout = params[dp])\n",
    "        val=params[hs] * 2\n",
    "        \n",
    "        # Initialize attention mechanism and log softmax layer\n",
    "        leng=len(preprocessed_data[ot])\n",
    "        self.concat , self.fc = nn.Linear(val, params[hs]),nn.Linear(params[hs], leng)\n",
    "        self.attn,self.log_softmax  = Attention(params[hs]),nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        # Perform forward pass of the Decoder_Attention_LSTM module\n",
    "        \n",
    "        # Embed the input token\n",
    "        outputs, (hidden, cell) = self.cell(self.dropout(self.embedding(x.unsqueeze(0))), (hidden, cell))\n",
    "        \n",
    "        # Apply attention to the LSTM outputs and encoder states\n",
    "        context = self.attn(outputs, encoder_states).bmm(encoder_states.transpose(0, 1))\n",
    "        \n",
    "        return self.log_softmax(self.fc(torch.tanh(self.concat(torch.cat((outputs.squeeze(0), context.squeeze(1)), 1))))), hidden, cell, self.attn(outputs, encoder_states).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Sequence-to-Sequence model with attention using LSTM\n",
    "class Seq2Seq_Attention_LSTM(nn.Module):\n",
    "    def __init__(self, encoder, decoder, params,  preprocessed_data):\n",
    "        nm='num_layers_dec'\n",
    "        super(Seq2Seq_Attention_LSTM, self).__init__()\n",
    "        leng=len(preprocessed_data['output_index'])\n",
    "        \n",
    "        # Extract parameters from params and preprocessed_data\n",
    "        self.encoder  = encoder\n",
    "        self.decoder  = decoder\n",
    "        self.output_index_len = leng\n",
    "        fr='teacher_fr'\n",
    "        self.num_layers_dec = params[nm]\n",
    "        self.tfr = params[fr]\n",
    "\n",
    "    def forward(self, source, target):\n",
    "         # Perform the forward pass of the Seq2Seq_Attention_LSTM module\n",
    "        \n",
    "        # Initialize the first input token (start of sequence) for decoding\n",
    "        x = target[0,:]# Start with the first token in the target sequence\n",
    "        \n",
    "        # Encode the source sequence using the encoder\n",
    "        encoder_op, hidden, cell = self.encoder(source)\n",
    "        \n",
    "        # Prepare a tensor to store the decoder outputs\n",
    "        outputs = torch.zeros(target.shape[0], source.shape[1], self.output_index_len)\n",
    "        outputs=outputs.to(device)\n",
    "                \n",
    "        # Restrict hidden and cell states to the decoder's number of layers\n",
    "        hidden =  hidden[:self.decoder.num_layers]\n",
    "        cell = cell[:self.decoder.num_layers]\n",
    "        \n",
    "        t=1\n",
    "        while t< target.shape[0]:\n",
    "            # Perform decoding step with attention using the decoder\n",
    "            output, hidden, cell, _ = self.decoder(x, encoder_op, hidden, cell)\n",
    "            \n",
    "            # Determine the next input token based on teacher forcing ratio\n",
    "            best_guess = output.argmax(1)\n",
    "            \n",
    "            # Store the decoder output in the outputs tensor\n",
    "            outputs[t] = output\n",
    "            x = best_guess if random.random() >= self.tfr else target[t]\n",
    "            t+=1\n",
    "        # Return the predicted outputs from the decoder for each time step    \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the optimizer based on specified parameters\n",
    "def get_optim(model, params):\n",
    "    # Extract the optimizer type from params and convert to lowercase\n",
    "    val = params['optimizer'].lower()\n",
    "    \n",
    "    if  val== 'sgd':\n",
    "        # Use Stochastic Gradient Descent (SGD) optimizer\n",
    "        opt = optim.SGD(model.parameters(), lr = params['learning_rate'], momentum = 0.9)\n",
    "    \n",
    "    if val == 'adagrad':\n",
    "        # Use adagrad optimizer\n",
    "        opt = optim.Adagrad(model.parameters(), lr = params['learning_rate'], lr_decay = 0, weight_decay = 0, initial_accumulator_value = 0, eps = 1e-10)\n",
    "    \n",
    "    if val == 'adam':\n",
    "        # Use adam optimizer\n",
    "        opt = optim.Adam(model.parameters(), lr = params['learning_rate'], betas = (0.9, 0.999), eps = 1e-8)\n",
    "    \n",
    "    if val == 'rmsprop':\n",
    "        # Use rmsprop optimizer\n",
    "        opt = optim.RMSprop(model.parameters(), lr = params['learning_rate'], alpha = 0.99, eps = 1e-8)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performs beam search using the specified model to predict a sequence for the input word.\n",
    "def beam_search(model, word, preprocessed_data, params, bw = 1, lp = 0.6): \n",
    "    # Prepare input sequence for encoding\n",
    "    val=preprocessed_data['max_len']+1\n",
    "    data = np.zeros((val, 1), dtype=np.int32)\n",
    "    idx = 0\n",
    "    while idx < len(word):\n",
    "        char = word[ idx ]\n",
    "        data[ idx , 0 ] = preprocessed_data['input_index'][char]\n",
    "        idx += 1\n",
    "        \n",
    "    # Append end-of-sequence token to the input sequence    \n",
    "    data[idx , 0] = preprocessed_data['input_index'][preprocessed_data['EOS']]\n",
    "    data = torch.tensor(data, dtype=torch.int32).to(device)\n",
    "    \n",
    "    # Perform encoding using the model\n",
    "    with torch.no_grad():\n",
    "        val=params['cell_type']\n",
    "        if  val != 'LSTM':\n",
    "            outputs, hidden = model.encoder(data)\n",
    "        else:\n",
    "            outputs, hidden, cell = model.encoder(data)\n",
    "            cell =  cell[:params['num_layers_dec']]\n",
    "     \n",
    "    # Prepare for beam search initialization\n",
    "    hidden =  hidden[:params['num_layers_dec']]\n",
    "    out_reshape = np.array(preprocessed_data['output_index'][preprocessed_data['SOS']]).reshape(1,)\n",
    "    hidden_par = hidden.unsqueeze(0)\n",
    "    initial_sequence = torch.tensor(out_reshape).to(device)\n",
    "    beam = [(0.0, initial_sequence, hidden_par)]\n",
    "    \n",
    "    # Perform beam search\n",
    "    i = 0\n",
    "    leng=len(preprocessed_data['output_index'])\n",
    "    while i < leng:\n",
    "        candidates = []\n",
    "        index = 0\n",
    "        # Expand each beam in the current step\n",
    "        while index < len(beam):\n",
    "            score, seq, hidden = beam[index]\n",
    "            val=seq[-1].item() == preprocessed_data['output_index'][preprocessed_data['EOS']]\n",
    "            \n",
    "            # Check if the sequence ends with the end-of-sequence token\n",
    "            if val:\n",
    "                candidates.append((score, seq, hidden))\n",
    "                index+=1\n",
    "                continue\n",
    "            reshape_last = np.array(seq[-1].item()).reshape(1,)\n",
    "            hdn = hidden.squeeze(0)\n",
    "            x = torch.tensor(reshape_last).to(device)\n",
    "            val=params['cell_type']\n",
    "            if  val!= 'LSTM':\n",
    "                output, hidden, _ = model.decoder(x, outputs, hdn, None)\n",
    "            else:\n",
    "                output, hidden, cell, _ = model.decoder(x, outputs, hdn, cell)\n",
    "            \n",
    "            # Apply softmax to the output and select top-k tokens\n",
    "            val=F.softmax(output, dim=1)\n",
    "            topk_probs, topk_tokens = torch.topk(val, k=bw)\n",
    "            \n",
    "            # Generate new candidate sequences\n",
    "            ii = 0\n",
    "            while ii < len(topk_probs[0]):\n",
    "                prob = topk_probs[0][ii]\n",
    "                token = topk_tokens[0][ii]\n",
    "                new_seq = torch.cat((seq, token.unsqueeze(0)), dim=0)\n",
    "                ln_ns = len(new_seq)\n",
    "                ln_pf = ((ln_ns - 1) / 5)\n",
    "                candidate_score = score + torch.log(prob).item() / (ln_pf ** lp)\n",
    "                candidates.append((candidate_score, new_seq, hidden.unsqueeze(0)))\n",
    "                ii += 1\n",
    "            index += 1\n",
    "        # Select the top-beam-width candidates\n",
    "        beam = heapq.nlargest(bw, candidates, key=lambda x: x[0])\n",
    "        i += 1\n",
    "    \n",
    "    # Retrieve the best sequence from the final beams    \n",
    "    m = max(beam, key=lambda x: x[0]) \n",
    "    _, best_sequence, _ = m\n",
    "    # Convert the best sequence to the predicted output\n",
    "    prediction = ''.join([preprocessed_data['output_index_rev'][token.item()] for token in best_sequence[1:]])    \n",
    "    \n",
    "    # Return the predicted sequence (excluding the EOS token)                                                                                                     \n",
    "    return prediction[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train(model, crit, optimizer, preprocessed_data, tensors, params):\n",
    "    val=1\n",
    "    bs='batch_size'\n",
    "    # Split the input and output data into batches\n",
    "    tr_result = torch.split(tensors['output_data'], params[bs], dim = val)\n",
    "    tr_data=torch.split(tensors['input_data'], params[bs], dim = val)\n",
    "    vl_result= torch.split(tensors['val_output_data'], params[bs], dim=val)\n",
    "    vl_data=torch.split(tensors['val_input_data'], params[bs], dim=val)\n",
    "    \n",
    "    # Loop through epochs\n",
    "    epoch = 0\n",
    "    while epoch < params['num_epochs'] :\n",
    "        epoch +=1\n",
    "        \n",
    "        # Initialize counters for metrics\n",
    "        correct_prediction,total_loss,total_words = 0,0,0\n",
    "        model.train()\n",
    "        leng=len(tr_data)\n",
    "        \n",
    "        # Use tqdm for progress visualization during training\n",
    "        val='Training'\n",
    "        with tqdm(total = leng, desc = val) as pbar:\n",
    "            index = 0\n",
    "            lenn = len(tr_data)\n",
    "            \n",
    "            # Loop through each batch in training data\n",
    "            while index < lenn:\n",
    "                # Move input and target data to device (e.g., GPU)\n",
    "                y = tr_result[index]\n",
    "                x = tr_data[index] \n",
    "                inp_data = x.to(device)\n",
    "                target= y.to(device) \n",
    "                optimizer.zero_grad()\n",
    "                output = model(inp_data, target)\n",
    "                \n",
    "                # Reshape target and output for loss calculation\n",
    "                target = target.reshape(-1)\n",
    "                output = output.reshape(-1, output.shape[2])\n",
    "                \n",
    "                # Create a mask to ignore padding tokens\n",
    "                pad_mask = (target != preprocessed_data['output_index'][preprocessed_data['PAD']])\n",
    "                output = output[pad_mask]\n",
    "                target = target[pad_mask]\n",
    "                \n",
    "                # Compute loss and perform backpropagation\n",
    "                loss = crit(output, target)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Update metrics\n",
    "                total_loss = total_loss +loss.item()\n",
    "                total_words = total_words + target.size(0)\n",
    "                correct_prediction = correct_prediction + torch.sum(torch.argmax(output, dim=1) == target).item()\n",
    "\n",
    "                index += 1\n",
    "                pbar.update(1)\n",
    "        \n",
    "        # Calculate training accuracy and loss\n",
    "        cal=correct_prediction / total_words\n",
    "        train_accuracy = cal * 100\n",
    "        len_train=len(tr_data)\n",
    "        train_loss = total_loss / len_train\n",
    "        model.eval()\n",
    "        \n",
    "        # Evaluate model on validation data\n",
    "        with torch.no_grad():\n",
    "            val_total_words,val_correct_pred,val_total_loss = 0,0,0\n",
    "            with tqdm(total = len(vl_data), desc = 'Validation') as pbar:\n",
    "                \n",
    "                index = 0\n",
    "                lenn=len(vl_data)\n",
    "                # Loop through each batch in validation data\n",
    "                while index < lenn:\n",
    "                    \n",
    "                    y_val =vl_result[index]\n",
    "                    x_val= vl_data[index]\n",
    "                    # Move validation input and target data to device\n",
    "                    inp_data_val = x_val.to(device)\n",
    "                    target_val=y_val.to(device)\n",
    "                    \n",
    "                    # Forward pass through the model for validation\n",
    "                    output_val = model(inp_data_val, target_val)\n",
    "                    target_val = target_val.reshape(-1)\n",
    "                    output_val = output_val.reshape(-1, output_val.shape[2])\n",
    "                    \n",
    "                    # Create mask to ignore padding tokens\n",
    "                    pad_mask = (target_val != preprocessed_data['output_index'][preprocessed_data['PAD']])\n",
    "                    output_val = output_val[pad_mask]\n",
    "                    target_val = target_val[pad_mask]\n",
    "                    \n",
    "                    # Calculate validation loss and metrics\n",
    "                    val_loss = crit(output_val, target_val)\n",
    "                    val_total_loss = val_total_loss+ val_loss.item()\n",
    "                    val_total_words = val_total_words+ target_val.size(0)\n",
    "                    val_correct_pred = val_correct_pred+ torch.sum(torch.argmax(output_val, dim=1) == target_val).item()\n",
    "                    index += 1\n",
    "                    pbar.update(1)\n",
    "            # Calculate validation accuracy and loss        \n",
    "            cal=val_correct_pred / val_total_words        \n",
    "            val_accuracy = cal * 100\n",
    "            lengg=len(vl_data)\n",
    "            val_loss = val_total_loss / lengg\n",
    "            \n",
    "            # Evaluate model using beam search and calculate word-level accuracy\n",
    "            correct_prediction = 0\n",
    "            total_words = len(preprocessed_data['val_words'])\n",
    "            with tqdm(total = total_words, desc = 'Beam') as pbar_:\n",
    "                index = 0\n",
    "                # Loop through each word in validation set for beam search evaluation\n",
    "                while index < len(preprocessed_data['val_words']):\n",
    "                    word, translation = preprocessed_data['val_words'][index], preprocessed_data['val_translations'][index]\n",
    "                    ans = beam_search(model, word, preprocessed_data, params, params['beam_width'], params['length_penalty'])\n",
    "                    val= translation[1:-1]\n",
    "                    # Check if beam search translation matches reference translation\n",
    "                    if ans == val:\n",
    "                        correct_prediction = correct_prediction +1\n",
    "\n",
    "                    index += 1\n",
    "                    pbar_.update(1)\n",
    "        # Calculate word-level accuracy using beam search            \n",
    "        cal=correct_prediction / total_words\n",
    "        val_accuracy_beam = cal * 100\n",
    "        \n",
    "        # Print and log results\n",
    "        print(f'''Epoch : {epoch}\n",
    "              Train Accuracy Char Level : {train_accuracy:.4f}, Train Loss : {train_loss:.4f}\n",
    "              Validation Accuracy Char Level : {val_accuracy:.4f}, Validation Loss : {val_loss:.4f}\n",
    "              Validation Accuracy Word Level : {val_accuracy_beam:.4f},  Correctly predicted : {correct_prediction}/{total_words}''')\n",
    "        if params['w_log']:\n",
    "            wandb.log(\n",
    "                    {\n",
    "                        'epoch': epoch,\n",
    "                        'training_loss' : train_loss,\n",
    "                        'training_accuracy_char' : train_accuracy,\n",
    "                        'validation_loss' : val_loss,\n",
    "                        'validation_accuracy_char' : val_accuracy,\n",
    "                        'validation_accuracy_word' : val_accuracy_beam,\n",
    "                        'correctly_predicted' : correct_correct_predictionpred\n",
    "                    }\n",
    "                )\n",
    "    # Return the trained model and validation accuracies    \n",
    "    return model, val_accuracy, val_accuracy_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passing parameters\n",
    "params = {\n",
    "#     'dataset_path' : r'C:\\Users\\gragh\\OneDrive\\Desktop\\Codes\\CS6910 DL\\Assignment 3\\DataSet\\aksharantar_sampled',\n",
    "    'language' : 'hin',\n",
    "    'dataset_path' : '/kaggle/input/dl-ass-3/aksharantar_sampled',\n",
    "    'embedding_size': 256,\n",
    "    'hidden_size': 512,\n",
    "    'num_layers_enc': 3,\n",
    "    'num_layers_dec': 3,\n",
    "    'cell_type': 'LSTM',\n",
    "    'dropout': 0.3,\n",
    "    'optimizer' : 'adagrad',\n",
    "    'learning_rate': 0.01,\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 1,\n",
    "    'teacher_fr' : 0.7,\n",
    "    'length_penalty' : 0.6,\n",
    "    'beam_width': 1,\n",
    "    'bi_dir' : True,\n",
    "    'w_log' : 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data based on the specified parameters\n",
    "preprocessed_data = loadData(params)\n",
    "tensors = create_tensor(preprocessed_data)\n",
    "\n",
    "# Initialize encoder, decoder, and seq2seq model based on cell type (LSTM or other)\n",
    "if params['cell_type'] == 'LSTM':\n",
    "    # Use LSTM-based encoder, decoder, and seq2seq model\n",
    "    encoder = Encoder_Attention_LSTM(params, preprocessed_data).to(device)\n",
    "    decoder = Decoder_Attention_LSTM(params, preprocessed_data).to(device)\n",
    "    model = Seq2Seq_Attention_LSTM(encoder, decoder, params, preprocessed_data).to(device) \n",
    "else:\n",
    "    # Use non-LSTM  based encoder, decoder, and seq2seq model\n",
    "    encoder = Encoder(params, preprocessed_data).to(device)\n",
    "    decoder = Decoder(params, preprocessed_data).to(device)\n",
    "    model = Seq2Seq(encoder, decoder, params, preprocessed_data).to(device)  \n",
    "# print(model)\n",
    "\n",
    "# Define the loss function (Cross Entropy Loss) ignoring padding tokens\n",
    "crit = nn.CrossEntropyLoss(ignore_index = 0)\n",
    "opt = get_optim(model,params)\n",
    "\n",
    "# Initialize logging with WandB if enabled\n",
    "if params['w_log']:\n",
    "    # Initialize a new WandB run with project name\n",
    "    wandb.init(project = 'DL-Assignment-3')\n",
    "    \n",
    "    # Set run name based on model and training hyperparameters for easy tracking\n",
    "    wandb.run.name = f\"c:{params['cell_type']}_e:{params['num_epochs']}_es:{params['embedding_size']}_hs:{params['hidden_size']}_nle:{params['num_layers_enc']}_nld:{params['num_layers_dec']}_o:{params['optimizer']}_lr:{params['learning_rate']}_bs:{params['batch_size']}_tf:{params['teacher_fr']}_lp:{params['length_penalty']}_b:{params['bi_dir']}_bw:{params['beam_width']}\"\n",
    "\n",
    "# Train the model using the defined training function\n",
    "# Obtain the trained model and validation accuracies    \n",
    "trained_model, _, _ = train(model, crit, opt, preprocessed_data, tensors, params)\n",
    "\n",
    "# Finish logging with WandB if enabled\n",
    "if params['w_log']:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the trained model to evaluation mode\n",
    "trained_model.eval()\n",
    "\n",
    "# Initialize variables for tracking predictions and evaluation\n",
    "correct_prediction = 0\n",
    "words = []\n",
    "translations = []\n",
    "prediction = []\n",
    "results = []\n",
    "\n",
    "# Use tqdm to visualize progress during inference\n",
    "total_words = len(preprocessed_data['test_words'])\n",
    "with tqdm(total = total_words) as pbar_:\n",
    "    index = 0\n",
    "    \n",
    "    # Loop through each word in the test set\n",
    "    while index < len(preprocessed_data['test_words']):\n",
    "        word, translation = preprocessed_data['test_words'][index], preprocessed_data['test_translations'][index]\n",
    "        \n",
    "        # Perform beam search to generate a translation using the trained model\n",
    "        ans = beam_search(trained_model, word, preprocessed_data,params, params['beam_width'], params['length_penalty'])\n",
    "        \n",
    "        # Store the word (without end token), translation (without start/end tokens), and predicted translation\n",
    "        words.append(word[:-1])\n",
    "        translations.append(translation[1:-1])\n",
    "        prediction.append(ans)\n",
    "        \n",
    "        # Check if the predicted translation matches the reference translation\n",
    "        val= ans == translation[1:-1]\n",
    "        if val!=1 :\n",
    "            results.append('No')\n",
    "        else:\n",
    "            correct_prediction = correct_prediction + 1\n",
    "            results.append('Yes')\n",
    "        index += 1\n",
    "        pbar_.update(1)\n",
    "        \n",
    "# Calculate accuracy based on correct predictions        \n",
    "cal=correct_prediction / total_words    \n",
    "accuracy = cal * 100\n",
    "print(f'Test Accuracy Word Level : {accuracy}, Correctly Predicted : {correct_prediction}')\n",
    "\n",
    "# Prepare a dictionary for logging predictions\n",
    "log = {'Word': words, 'Translation' : translations, 'Prediction' : prediction, 'Result' : results}\n",
    "path = '/kaggle/working/predictions_vanilla.csv'\n",
    "\n",
    "# Create a DataFrame from the logging dictionary and save it as a CSV file\n",
    "data_frame = pd.DataFrame(log)\n",
    "data_frame.to_csv(path, header = True, index = False)\n",
    "# Optionally display the DataFrame (for debugging or verification)\n",
    "pd.DataFrame(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for the prediction in heatmaps\n",
    "def predict(model, word, preprocessed_data, params):\n",
    "    # Determine the maximum length for the input sequence\n",
    "    val=preprocessed_data['max_len'] + 1\n",
    "    pred = ''\n",
    "    \n",
    "    # Initialize a numpy array for encoding the input word\n",
    "    data = np.zeros((val,1), dtype= int)\n",
    "    \n",
    "    # Map characters of the input word to their corresponding indices\n",
    "    ii='input_index'\n",
    "    for t , char in enumerate(word):\n",
    "        data[t, 0] = preprocessed_data[ii][char]\n",
    "    \n",
    "    #Append the end-of-sequence token to the encoded input\n",
    "    data[(t+1),0] = preprocessed_data[ii][preprocessed_data['EOS']]\n",
    "    nm='num_layers_dec'\n",
    "    \n",
    "    # Convert the numpy array to a PyTorch tensor and move it to the appropriate device (e.g., GPU)\n",
    "    data = torch.tensor(data,dtype = torch.int64)\n",
    "    data=data.to(device)\n",
    "    oi='output_index'\n",
    "    \n",
    "    # Disable gradient calculation during inference\n",
    "    with torch.no_grad():\n",
    "        val=params['cell_type']\n",
    "        # Encode the input sequence using the model's encoder\n",
    "        if  val!= 'LSTM':\n",
    "            outputs, hidden = model.encoder(data)\n",
    "        else:\n",
    "            outputs, hidden, cell = model.encoder(data)\n",
    "            cell =  cell[:params[nm]]\n",
    "    # Extract the hidden state from the encoder outputs        \n",
    "    hidden = hidden[:params[nm]]\n",
    "    \n",
    "    # Initialize the input tensor with the start-of-sequence token\n",
    "    x = torch.tensor([preprocessed_data[oi][preprocessed_data['SOS']]])\n",
    "    x=x.to(device)\n",
    "    \n",
    "    # Initialize variables for attention mechanism\n",
    "    leng=preprocessed_data['max_len'] + 1\n",
    "    attentions = torch.zeros(preprocessed_data['max_len'] + 1, 1, leng)\n",
    "    oir='output_index_rev'\n",
    "    \n",
    "    # Perform decoding to generate the output sequence\n",
    "    t = 1\n",
    "    while t < len(preprocessed_data[oi]):\n",
    "        # Determine the type of RNN cell used in the model\n",
    "        val=params['cell_type']\n",
    "        # Decode the next character using the model's decoder\n",
    "        if  val!= 'LSTM':\n",
    "            output, hidden, attn = model.decoder(x, outputs, hidden, None)\n",
    "        else:\n",
    "            output, hidden, cell, attn = model.decoder(x, outputs, hidden, cell)\n",
    "        \n",
    "        # Map the predicted character index to the actual character\n",
    "        val=output.argmax(1).item()\n",
    "        character = preprocessed_data[oir][val]\n",
    "        attentions[t] = attn\n",
    "        \n",
    "        # Check if the predicted character is the end-of-sequence token\n",
    "        val=character == preprocessed_data['EOS']\n",
    "        if val:\n",
    "            break\n",
    "        else:\n",
    "            pred = pred + character\n",
    "            \n",
    "        # Update the input tensor with the predicted character for the next decoding step\n",
    "        x = torch.tensor([output.argmax(1)]).to(device) \n",
    "        t+=1\n",
    "    return pred, attentions[:t+1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot the attention grid\n",
    "def plot_attention_grid(words, translations, attentions):\n",
    "    # Set the figure size for the plot\n",
    "    val=15\n",
    "     # Set the title of the plot\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(val,val))\n",
    "    fig.suptitle('Attention Matrix Grid', fontsize=14)\n",
    "    \n",
    "    # Iterate over the first 10 samples to plot attention matrices\n",
    "    i=0 \n",
    "    while i< 10:\n",
    "        translation , word= translations[i] , words[i]\n",
    "        # Retrieve attention matrix for the current translation and word pair\n",
    "        attention = attentions[i][:len(translation), :len(word)]\n",
    "        attention=attention.squeeze(1).detach()\n",
    "        attetion=attention.numpy()\n",
    "        # Plot the attention matrix\n",
    "        ax = axes.flat[i]\n",
    "        ax.matshow(attention.numpy(), cmap='YlGnBu')\n",
    "        \n",
    "        # Set y-axis ticks and labels\n",
    "        lengg=len(translation)\n",
    "        ax.set_yticks(np.arange(lengg))\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        leng=len(word)\n",
    "        ax.set_xticklabels(word, size=8)\n",
    "        ax.set_xticks(np.arange(leng))\n",
    "        iss='Input Sequence'\n",
    "        \n",
    "        # Set labels for x-axis and y-axis\n",
    "        ax.set_yticklabels(translation, size=8, fontproperties = FontProperties(fname='/kaggle/input/wordcloud-hindi-font/Nirmala.ttf'))\n",
    "        ax.set_xlabel(iss, fontsize=10)\n",
    "        os='Output Sequence'\n",
    "        ax.set_ylabel(os, fontsize=10)\n",
    "        col='lightgray'\n",
    "        ax.grid(color=col, linestyle='-', linewidth=1)\n",
    "        i+=1\n",
    "    \n",
    "    # Hide remaining subplot axes (if any)\n",
    "    flat_axes = axes.flat\n",
    "    num_axes=len(flat_axes)\n",
    "    i=10\n",
    "    while i < num_axes:\n",
    "        ax = flat_axes[i]\n",
    "        ax.axis('off')\n",
    "        i += 1\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store inputs, predicted outputs, and corresponding attentions\n",
    "attentions =[]\n",
    "inputs=[]\n",
    "outputs=[]\n",
    "\n",
    "# Zip the test words and translations together\n",
    "val=zip(preprocessed_data['test_words'], preprocessed_data['test_translations'])\n",
    "# Randomly select 10 word-translation pairs for visualization\n",
    "random_pairs = random.sample(list(val), 10)\n",
    "\n",
    "# Enumerate over the randomly selected pairs\n",
    "val=enumerate(random_pairs)\n",
    "for i, (w, t) in val:\n",
    "    # Extract the translation and word (remove end tokens)\n",
    "    translation = t[:-1]\n",
    "    word=w[:-1]\n",
    "    \n",
    "    # Use the trained model to predict the translation and capture attention\n",
    "    output, attention = predict(trained_model, word, preprocessed_data, params)\n",
    "    \n",
    "    # Append the input word (without end token) to the inputs list\n",
    "    inputs.append(w[:-1])\n",
    "    \n",
    "    # Append the predicted output (with a leading space for visualization) to the outputs list\n",
    "    outputs.append(' '+output)\n",
    "    \n",
    "    # Append the attention matrix (limited to the length of the input word) to the attentions list\n",
    "    attentions.append(attention[:, :, :(len(w[:-1]))])\n",
    "    \n",
    "# Visualize the attention matrices using a custom plotting function    \n",
    "plot_attention_grid(inputs, outputs, attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
