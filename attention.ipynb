{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import heapq\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val=torch.cuda.is_available()\n",
    "if val == 1:\n",
    "    device= torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('gpu')\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(params):\n",
    "    dataset_path = params['dataset_path']\n",
    "    train_data = csv.reader(open(dataset_path + '/hin/hin_train.csv',encoding='utf8'))\n",
    "    val_data = csv.reader(open(dataset_path + '/hin/hin_valid.csv',encoding='utf8'))\n",
    "    test_data = csv.reader(open(dataset_path + '/hin/hin_test.csv',encoding='utf8'))\n",
    "    train_translations = []\n",
    "    test_words=[]\n",
    "    val_translations = []\n",
    "    val_words=[]\n",
    "    train_words =[]\n",
    "    test_translations = []\n",
    "    pad=''\n",
    "    start='$'\n",
    "    end ='&' \n",
    "    train_data_list = list(train_data)\n",
    "    train_len = len(train_data_list)\n",
    "    i = 0\n",
    "    while i < train_len:\n",
    "        pair = train_data_list[i]\n",
    "        train_words.append(pair[0] + end)\n",
    "        train_translations.append(start + pair[1] + end)\n",
    "        i += 1  \n",
    "    \n",
    "    i=0\n",
    "    val_data_list = list(val_data)\n",
    "    val_len = len(val_data_list)\n",
    "    while i < val_len :\n",
    "        pair=val_data_list[i]\n",
    "        val_words.append(pair[0]+end)\n",
    "        val_translations.append(start+pair[1]+end)\n",
    "        i+=1\n",
    "        \n",
    "    i=0\n",
    "    test_data_list = list(test_data)\n",
    "    test_len = len(test_data_list)\n",
    "    while i < test_len :\n",
    "        pair=test_data_list[i]\n",
    "        test_words.append(pair[0]+end)\n",
    "        test_translations.append(start+pair[1]+end)\n",
    "        i+=1   \n",
    "        \n",
    " \n",
    "    \n",
    "    test_words =np.array(test_words)\n",
    "    train_translations = np.array(train_translations)\n",
    "    val_translations =np.array(val_translations)\n",
    "    train_words = np.array(train_words)\n",
    "    test_translations = np.array(test_translations)\n",
    "    val_words =np.array(val_words)\n",
    "    \n",
    "    \n",
    "    \n",
    "    output_vocab,input_vocab = set() , set()\n",
    "    i = 0\n",
    "    word_len=len(train_words)\n",
    "    while i < word_len :\n",
    "        word = train_words[i]\n",
    "        character_index = 0\n",
    "        while character_index < len(word):\n",
    "            character = word[character_index]\n",
    "            input_vocab.add(character)\n",
    "            character_index += 1\n",
    "        i += 1         \n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    word_len=len(val_words)\n",
    "    while i < word_len :\n",
    "        word = val_words[i]\n",
    "        character_index = 0\n",
    "        while character_index < len(word):\n",
    "            character = word[character_index]\n",
    "            input_vocab.add(character)\n",
    "            character_index += 1\n",
    "        i += 1\n",
    "    \n",
    "    i = 0\n",
    "    word_len=len(test_words)\n",
    "    while i < word_len :\n",
    "        word = test_words[i]\n",
    "        character_index = 0\n",
    "        while character_index < len(word):\n",
    "            character = word[character_index]\n",
    "            input_vocab.add(character)\n",
    "            character_index += 1\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    word_len=len(train_translations)\n",
    "    while i < word_len :\n",
    "        word = train_translations[i]\n",
    "        character_index = 0\n",
    "        while character_index < len(word):\n",
    "            character = word[character_index]\n",
    "            output_vocab.add(character)\n",
    "            character_index += 1\n",
    "        i += 1\n",
    "        \n",
    "    i = 0\n",
    "    word_len=len(val_translations)\n",
    "    while i < word_len :\n",
    "        word = val_translations[i]\n",
    "        character_index = 0\n",
    "        while character_index < len(word):\n",
    "            character = word[character_index]\n",
    "            output_vocab.add(character)\n",
    "            character_index += 1\n",
    "        i += 1\n",
    "        \n",
    "    i = 0\n",
    "    word_len=len(test_translations)\n",
    "    while i < word_len :\n",
    "        word = test_translations[i]\n",
    "        character_index = 0\n",
    "        while character_index < len(word):\n",
    "            character = word[character_index]\n",
    "            output_vocab.add(character)\n",
    "            character_index += 1\n",
    "        i += 1\n",
    "    \n",
    "    output_vocab.remove(start)\n",
    "    input_vocab.remove(end)\n",
    "    output_vocab.remove(end)\n",
    "    \n",
    "    output_vocab= [pad, start, end] + list(sorted(output_vocab))\n",
    "    input_vocab = [pad, start, end] + list(sorted(input_vocab))\n",
    "            \n",
    " \n",
    "    output_index,input_index = {char: idx for idx, char in enumerate(output_vocab)},{char: idx for idx, char in enumerate(input_vocab)}\n",
    "    output_index_rev,input_index_rev = {idx: char for char, idx in output_index.items()},{idx: char for char, idx in input_index.items()}\n",
    "    \n",
    "\n",
    "    max_len = max(max([len(word) for word in np.hstack((train_words, test_words, val_words))]), max([len(word) for word in np.hstack((train_translations, val_translations, test_translations))]))\n",
    "        \n",
    "    preprocessed_data = {\n",
    "        'SOS' : start,\n",
    "        'EOS' : end,\n",
    "        'PAD' : pad,\n",
    "        'train_words' : train_words,\n",
    "        'train_translations' : train_translations,\n",
    "        'val_words' : val_words,\n",
    "        'val_translations' : val_translations,\n",
    "        'test_words' : test_words,\n",
    "        'test_translations' : test_translations,\n",
    "        'max_enc_len' : max([len(word) for word in np.hstack((train_words, test_words, val_words))]),\n",
    "        'max_dec_len' : max([len(word) for word in np.hstack((train_translations, val_translations, test_translations))]),\n",
    "        'max_len' : max_len,\n",
    "        'input_index' : input_index,\n",
    "        'output_index' : output_index,\n",
    "        'input_index_rev' : input_index_rev,\n",
    "        'output_index_rev' : output_index_rev\n",
    "    }\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor(preprocessed_data):\n",
    "    prop_data=preprocessed_data['max_len']\n",
    "    leng=len(preprocessed_data['train_words'])\n",
    "    d_type='int64'\n",
    "    input_data = np.zeros((prop_data,leng), dtype = d_type)\n",
    "    output_data = np.zeros((prop_data,leng), dtype = d_type)\n",
    "    leng=len(preprocessed_data['val_words'])\n",
    "    val_input_data = np.zeros((prop_data,leng), dtype = d_type)\n",
    "    val_output_data = np.zeros((prop_data,leng), dtype = d_type)\n",
    "    leng=len(preprocessed_data['test_words'])\n",
    "    test_input_data = np.zeros((prop_data,leng), dtype = d_type)\n",
    "    test_output_data = np.zeros((prop_data,leng), dtype = d_type)\n",
    "    \n",
    "\n",
    "    idx = 0\n",
    "    while idx < len(preprocessed_data['train_words']):\n",
    "        w = preprocessed_data['train_words'][idx]\n",
    "        t = preprocessed_data['train_translations'][idx]\n",
    "\n",
    "        i = 0\n",
    "        while i < len(w):\n",
    "            char = w[i]\n",
    "            input_data[i, idx] = preprocessed_data['input_index'][char]\n",
    "            i += 1\n",
    "\n",
    "        i = 0\n",
    "        while i < len(t):\n",
    "            char = t[i]\n",
    "            output_data[i, idx] = preprocessed_data['output_index'][char]\n",
    "            i += 1\n",
    "        idx += 1            \n",
    "        \n",
    "\n",
    "            \n",
    "    idx = 0\n",
    "    while idx < len(preprocessed_data['val_words']):\n",
    "        w = preprocessed_data['val_words'][idx]\n",
    "        t = preprocessed_data['val_translations'][idx]\n",
    "\n",
    "        i = 0\n",
    "        while i < len(w):\n",
    "            char = w[i]\n",
    "            val_input_data[i, idx] = preprocessed_data['input_index'][char]\n",
    "            i += 1\n",
    "\n",
    "        i = 0\n",
    "        while i < len(t):\n",
    "            char = t[i]\n",
    "            val_output_data[i, idx] = preprocessed_data['output_index'][char]\n",
    "            i += 1\n",
    "        idx += 1            \n",
    "        \n",
    "            \n",
    "    idx = 0\n",
    "    while idx < len(preprocessed_data['test_words']):\n",
    "        w = preprocessed_data['test_words'][idx]\n",
    "        t = preprocessed_data['test_translations'][idx]\n",
    "\n",
    "        i = 0\n",
    "        while i < len(w):\n",
    "            char = w[i]\n",
    "            test_input_data[i, idx] = preprocessed_data['input_index'][char]\n",
    "            i += 1\n",
    "\n",
    "        i = 0\n",
    "        while i < len(t):\n",
    "            char = t[i]\n",
    "            test_output_data[i, idx] = preprocessed_data['output_index'][char]\n",
    "            i += 1\n",
    "        idx += 1            \n",
    "        \n",
    "            \n",
    "            \n",
    "    output_data=torch.tensor(output_data, dtype = torch.int64)\n",
    "    input_data = torch.tensor(input_data,dtype = torch.int64)\n",
    "    val_output_data=torch.tensor(val_output_data, dtype = torch.int64)\n",
    "    val_input_data = torch.tensor(val_input_data,dtype = torch.int64)\n",
    "    test_output_data=torch.tensor(test_output_data, dtype = torch.int64)\n",
    "    test_input_data= torch.tensor(test_input_data,dtype = torch.int64)\n",
    "    \n",
    "    tensors = {\n",
    "        'input_data' : input_data,\n",
    "        'output_data' : output_data,\n",
    "        'val_input_data' : val_input_data,\n",
    "        'val_output_data' : val_output_data, \n",
    "        'test_input_data' : test_input_data,\n",
    "        'test_output_data' : test_output_data\n",
    "    }\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        val=hidden_size\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = val\n",
    "    def dot_score(self,hidden_state, encoder_states):\n",
    "        cal = torch.sum(hidden_state * encoder_states, dim=2)\n",
    "        return cal\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        cal = F.softmax(self.dot_score(hidden, encoder_outputs).t(), dim=1).unsqueeze(1)\n",
    "        return cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, params, preprocessed_data):\n",
    "        hd='hidden_size'\n",
    "        dp='dropout'\n",
    "        super(Encoder_Attention, self).__init__() \n",
    "        self.bi_directional,self.cell_type = params['bi_dir'],params['cell_type']\n",
    "        leng=len(preprocessed_data['input_index'])\n",
    "        self.dropout,self.embedding = nn.Dropout(params[dp]),nn.Embedding(leng, params[es])\n",
    "        self.hidden_size = params[hd]\n",
    "        val=self.cell_type\n",
    "        nm='num_layers_enc'\n",
    "        es='embedding_size' \n",
    "        if val == 'GRU':\n",
    "            self.cell = nn.GRU(params[es], params[hd], params[nm], dropout = params[dp], bidirectional = self.bi_directional)\n",
    "        if val == 'RNN':\n",
    "            self.cell = nn.RNN(params[es], params[hd], params[nm], dropout = params[dp], bidirectional = self.bi_directional)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoder_states, hidden = self.cell(self.dropout(self.embedding(x)))\n",
    "        val=self.bi_directional\n",
    "        if val:\n",
    "            encoder_states = encoder_states[:, :, :self.hidden_size] + encoder_states[:, : ,self.hidden_size:]\n",
    "        return encoder_states, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_Attention(nn.Module):\n",
    "    def __init__(self, params, preprocessed_data):\n",
    "        \n",
    "        # Initialize the Decoder_Attention module\n",
    "        super(Decoder_Attention, self).__init__()\n",
    "        dp = 'dropout'\n",
    "        \n",
    "        # Define dropout layer and embedding layer\n",
    "        self.dropout = nn.Dropout(params[dp])\n",
    "        ct,nm = 'cell_type','num_layers_dec'\n",
    "        self.num_layers,self.cell_type= params[nm] , params[ct]\n",
    "        es = 'embedding_size'\n",
    "        leng = len(preprocessed_data['output_index'])\n",
    "        self.embedding = nn.Embedding(leng, params[es])\n",
    "        hs = 'hidden_size'\n",
    "        val=self.cell_type\n",
    "        \n",
    "        # Initialize RNN cell based on cell_type\n",
    "        if val == 'GRU':\n",
    "            self.cell = nn.GRU(params[es], params[hs], self.num_layers, dropout = params[dp])\n",
    "        if val == 'RNN':\n",
    "            self.cell = nn.RNN(params[es], params[hs], self.num_layers, dropout = params[dp])\n",
    "        val = params[hs] * 2\n",
    "        leng = len(preprocessed_data['output_index'])\n",
    "        self.fc , self.concat = nn.Linear(params[hs], leng),nn.Linear(val, params[hs])\n",
    "        self.log_softmax , self.attn = nn.LogSoftmax(dim=1),Attention(params[hs])\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        \n",
    "        # Perform forward pass of the Decoder_Attention module\n",
    "        # Embed input token (unsqueeze to add batch dimension)\n",
    "        outputs, (hidden) = self.cell(self.dropout(self.embedding(x.unsqueeze(0))), hidden)\n",
    "        context = self.attn(outputs, encoder_states).bmm(encoder_states.transpose(0, 1))\n",
    "        return self.log_softmax(self.fc(torch.tanh(self.concat(torch.cat((outputs.squeeze(0), context.squeeze(1)), 1))))), hidden, attention_weights.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sequence-to-sequence model with attention mechanism\n",
    "class Seq2Seq_Attention(nn.Module):\n",
    "    # Initialize the Seq2Seq_Attention module\n",
    "    def __init__(self, encoder, decoder, params,  preprocessed_data):\n",
    "        super(Seq2Seq_Attention, self).__init__()\n",
    "        # Extract necessary parameters from the params dictionary\n",
    "        nm='num_layers_dec'\n",
    "        leng=len(preprocessed_data['output_index'])\n",
    "        self.output_index_len = leng\n",
    "        tf= 'teacher_fr'\n",
    "        self.tfr = params[tf]\n",
    "        self.num_layers_dec = params[nm]\n",
    "        \n",
    "        # Set encoder and decoder modules\n",
    "        self.encoder  = encoder\n",
    "        self.decoder  = decoder \n",
    "        \n",
    "        \n",
    "    def forward(self, source, target):\n",
    "        # Perform forward pass of the Seq2Seq_Attention module\n",
    "        \n",
    "        # Initialize decoder input (start token)\n",
    "        x = target[0,:]\n",
    "        \n",
    "        # Encode the source sequence using the encoder\n",
    "        encoder_op, hidden = self.encoder(source)\n",
    "        \n",
    "        # Initialize output tensor for predictions\n",
    "        outputs = torch.zeros(target.shape[0], source.shape[1], self.output_index_len)\n",
    "        outputs=outputs.to(device)\n",
    "        \n",
    "        # Limit decoder hidden state to the specified number of layers\n",
    "        hidden =  hidden[:self.decoder.num_layers]\n",
    "        t = 1\n",
    "        while t < target.shape[0] :  \n",
    "            # Perform decoding step using the decoder module\n",
    "            output, hidden, _ = self.decoder(x, encoder_op, hidden, None)\n",
    "            # Determine the next input token based on teacher forcing ratio\n",
    "            best_guess = output.argmax(1)\n",
    "            # Store the output predictions\n",
    "            outputs[t] = output\n",
    "            x = best_guess if random.random() >= self.tfr else target[t]\n",
    "            t+=1\n",
    "        # Return the predicted outputs from the decoder    \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an Encoder module with attention using LSTM\n",
    "class Encoder_Attention_LSTM(nn.Module):\n",
    "    ct='cell_type'\n",
    "    bi='bi_dir'\n",
    "    def __init__(self, params, preprocessed_data):\n",
    "        \n",
    "        #Initialize the Encoder_Attention_LSTM module\n",
    "        super(Encoder_Attention_LSTM, self).__init__()\n",
    "        self.cell_type = params['cell_type']\n",
    "        self.bi_directional = params['bi_dir']\n",
    "        es='embedding_size'\n",
    "        leng=len(preprocessed_data['input_index'])\n",
    "        self.embedding = nn.Embedding(leng, params[es])\n",
    "        dp='dropout'\n",
    "        hs='hidden_size'\n",
    "        self.hidden_size = params[hs]\n",
    "        nm='num_layers_enc'\n",
    "        self.dropout = nn.Dropout(params[dp])\n",
    "        \n",
    "        # Initialize LSTM cell\n",
    "        self.cell = nn.LSTM(params[es], params[hs], params[nm], dropout = params[dp], bidirectional = self.bi_directional)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform forward pass of the Encoder_Attention_LSTM module\n",
    "        \n",
    "        # Embed the input sequence\n",
    "        encoder_states, (hidden, cell) = self.cell(self.dropout(self.embedding(x)))\n",
    "        \n",
    "        # If bidirectional, concatenate the states from both directions\n",
    "        val=self.bi_directional\n",
    "        if val:\n",
    "            encoder_states = encoder_states[:, :, :self.hidden_size] + encoder_states[:, : ,self.hidden_size:]\n",
    "        \n",
    "        # Return encoder, hidden and cell states    \n",
    "        return encoder_states, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Decoder module with attention using LSTM\n",
    "class Decoder_Attention_LSTM(nn.Module):\n",
    "    def __init__(self, params, preprocessed_data):\n",
    "        \n",
    "        # Initialize the Decoder_Attention_LSTM module\n",
    "        super(Decoder_Attention_LSTM, self).__init__()\n",
    "        nm='num_layers_dec'\n",
    "        dp='dropout'\n",
    "        \n",
    "        # Set up dropout layer\n",
    "        self.dropout = nn.Dropout(params[dp])\n",
    "        self.num_layers = params[nm]\n",
    "        ot='output_index'\n",
    "        \n",
    "        # Initialize embedding layer based on output vocabulary size and embedding size\n",
    "        leng=len(preprocessed_data[ot])\n",
    "        es='embedding_size'\n",
    "        self.embedding = nn.Embedding(leng, params[es])\n",
    "        hs='hidden_size'\n",
    "        \n",
    "        # Initialize LSTM cell for decoding\n",
    "        self.cell = nn.LSTM(params[es], params[hs], self.num_layers, dropout = params[dp])\n",
    "        val=params[hs] * 2\n",
    "        \n",
    "        # Initialize attention mechanism and log softmax layer\n",
    "        leng=len(preprocessed_data[ot])\n",
    "        self.concat , self.fc = nn.Linear(val, params[hs]),nn.Linear(params[hs], leng)\n",
    "        self.attn,self.log_softmax  = Attention(params[hs]),nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        # Perform forward pass of the Decoder_Attention_LSTM module\n",
    "        \n",
    "        # Embed the input token\n",
    "        outputs, (hidden, cell) = self.cell(self.dropout(self.embedding(x.unsqueeze(0))), (hidden, cell))\n",
    "        \n",
    "        # Apply attention to the LSTM outputs and encoder states\n",
    "        context = self.attn(outputs, encoder_states).bmm(encoder_states.transpose(0, 1))\n",
    "        \n",
    "        return self.log_softmax(self.fc(torch.tanh(self.concat(torch.cat((outputs.squeeze(0), context.squeeze(1)), 1))))), hidden, cell, self.attn(outputs, encoder_states).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Sequence-to-Sequence model with attention using LSTM\n",
    "class Seq2Seq_Attention_LSTM(nn.Module):\n",
    "    def __init__(self, encoder, decoder, params,  preprocessed_data):\n",
    "        nm='num_layers_dec'\n",
    "        super(Seq2Seq_Attention_LSTM, self).__init__()\n",
    "        leng=len(preprocessed_data['output_index'])\n",
    "        \n",
    "        # Extract parameters from params and preprocessed_data\n",
    "        self.encoder  = encoder\n",
    "        self.decoder  = decoder\n",
    "        self.output_index_len = leng\n",
    "        fr='teacher_fr'\n",
    "        self.num_layers_dec = params[nm]\n",
    "        self.tfr = params[fr]\n",
    "\n",
    "    def forward(self, source, target):\n",
    "         # Perform the forward pass of the Seq2Seq_Attention_LSTM module\n",
    "        \n",
    "        # Initialize the first input token (start of sequence) for decoding\n",
    "        x = target[0,:]# Start with the first token in the target sequence\n",
    "        \n",
    "        # Encode the source sequence using the encoder\n",
    "        encoder_op, hidden, cell = self.encoder(source)\n",
    "        \n",
    "        # Prepare a tensor to store the decoder outputs\n",
    "        outputs = torch.zeros(target.shape[0], source.shape[1], self.output_index_len)\n",
    "        outputs=outputs.to(device)\n",
    "                \n",
    "        # Restrict hidden and cell states to the decoder's number of layers\n",
    "        hidden =  hidden[:self.decoder.num_layers]\n",
    "        cell = cell[:self.decoder.num_layers]\n",
    "        \n",
    "        t=1\n",
    "        while t< target.shape[0]:\n",
    "            # Perform decoding step with attention using the decoder\n",
    "            output, hidden, cell, _ = self.decoder(x, encoder_op, hidden, cell)\n",
    "            \n",
    "            # Determine the next input token based on teacher forcing ratio\n",
    "            best_guess = output.argmax(1)\n",
    "            \n",
    "            # Store the decoder output in the outputs tensor\n",
    "            outputs[t] = output\n",
    "            x = best_guess if random.random() >= self.tfr else target[t]\n",
    "            t+=1\n",
    "        # Return the predicted outputs from the decoder for each time step    \n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
